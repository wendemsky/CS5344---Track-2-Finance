\documentclass[12pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{microtype} % better line breaking / justification
\usepackage{hyperref}
\usepackage[htt]{hyphenat} % allow hyphenation in long identifiers

% Hyperref link colors (no red in ToC)
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=blue,
    citecolor=black
}

% Table column helpers and spacing
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}
\renewcommand{\arraystretch}{1.2}

% Slightly relax line breaking to avoid overfull boxes in dense tables
\sloppy

% Header and footer setup
\pagestyle{fancy}
\fancyhf{}
\rhead{CS5344 Big Data Analytics}
\lhead{Loan Anomaly Detection}
\cfoot{\thepage}

\title{\textbf{Loan Anomaly Detection for Repayment Behavior Analysis} \\
       \large CS5344 Big Data Analytics Track 2: Finance}
\author{Team Project Proposal}
\date{\today}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Introduction}

In the modern financial landscape, accurate prediction of loan defaults is crucial for risk management and maintaining portfolio stability. Traditional credit scoring models primarily rely on static borrower characteristics at loan origination, potentially missing dynamic patterns that emerge during the loan lifecycle. This project addresses the challenge of \textbf{loan-level anomaly detection for repayment behavior}, where we analyze both static borrower information and temporal performance sequences to identify loans that exhibit abnormal repayment patterns.

The problem is formulated as a semi-supervised learning task where the training dataset contains exclusively normal loans (loans that meet their obligations), while the validation and test sets include both normal and abnormal loans. This mirrors real-world scenarios where financial institutions have abundant historical data on performing loans but limited labeled examples of defaults during model development phases.

Our approach leverages the rich temporal structure inherent in loan performance data, combining static origination features with dynamic monthly performance indicators to detect anomalous repayment behaviors that may signal impending default or other adverse outcomes.

\section{Project Objective}

The primary objective of this project is to develop a robust anomaly detection system capable of identifying loans with abnormal repayment patterns using a combination of static borrower characteristics and temporal performance sequences. Specifically, we aim to:

\begin{itemize}[itemsep=0.5em]
    \item \textbf{Primary Goal}: Maximize the Average Precision (AUPRC) score for detecting abnormal loans in an imbalanced dataset (87.39\% normal vs 12.61\% abnormal)

    \item \textbf{Methodological Objective}: Design a semi-supervised learning framework that effectively learns normal loan behavior patterns from training data containing only normal loans

    \item \textbf{Technical Objective}: Develop sophisticated feature engineering techniques that capture both static risk factors and temporal dynamics in loan performance

    \item \textbf{Practical Objective}: Create an interpretable and scalable solution suitable for deployment in real-world financial risk management systems
\end{itemize}

The success of our approach will be measured primarily by the Average Precision metric, which is particularly appropriate for imbalanced binary classification problems as it focuses on the precision-recall trade-off rather than overall accuracy.

\section{Target Task}

Our target task is \textbf{semi-supervised anomaly detection} in the financial domain, specifically focused on loan repayment behavior analysis. The task characteristics include:

\textbf{Problem Type}: Binary classification where we predict whether a loan exhibits normal (0) or abnormal (1) repayment behavior patterns.

\textbf{Learning Paradigm}: Semi-supervised learning, as the training data contains only normal examples (30{,}504 loans with target=0), while validation data contains both classes (4{,}693 normal, 677 abnormal loans).

\textbf{Data Structure}: Each loan $i$ is represented as:
\begin{equation}
x_i = (s_i, (t_{i,1}, r_{i,1}), (t_{i,2}, r_{i,2}), \ldots, (t_{i,T_i}, r_{i,T_i}), y_i)
\end{equation}

Where:
\begin{itemize}
    \item $s_i$ = static loan information (borrower attributes, loan terms)
    \item $\{t_{i,k}\}_{k=1}^{T_i}$ = time periods with $t_{i,1} < \ldots < t_{i,T_i}$
    \item $T_i = 14$ = number of months for loan $i$ (consistent across dataset)
    \item $r_{i,k}$ = monthly repayment information vector at time $t_{i,k}$
    \item $y_i \in \{0, 1\}$ = binary label (0=normal, 1=abnormal)
\end{itemize}

The challenge lies in learning meaningful representations that capture both static risk factors and temporal patterns indicative of abnormal repayment behavior, without having access to labeled abnormal examples during the training phase.

\section{Dataset}

Our dataset consists of loan-level data from the Freddie Mac Single-Family Loan-Level Dataset, structured as follows:

\textbf{Dataset Composition}:
\begin{itemize}
    \item \textbf{Training Set}: 30{,}504 loans $\times$ 145 features (100\% normal loans)
    \item \textbf{Validation Set}: 5{,}370 loans $\times$ 145 features (87.39\% normal, 12.61\% abnormal)
    \item \textbf{Test Set}: 13{,}426 loans $\times$ 144 features (unlabeled for competition submission)
\end{itemize}

\textbf{Feature Structure}:
\begin{itemize}
    \item \textbf{Static Features (31)}: Origination variables including borrower credit score (mean=753.6, std=156.1), original unpaid principal balance (mean=\$317K, std=\$181K), loan-to-value ratio (mean=75.2\%, std=19.4\%), original interest rate (mean=6.72\%, std=0.55\%), debt-to-income ratio, loan terms, property characteristics, and demographic information

    \item \textbf{Temporal Features (112)}: Monthly performance data spanning exactly 14 months for all loans, with 8 performance metrics tracked monthly: CurrentActualUPB, CurrentInterestRate, CurrentNonInterestBearingUPB, EstimatedLTV, InterestBearingUPB, LoanAge, MonthlyReportingPeriod, and RemainingMonthsToLegalMaturity

    \item \textbf{Target Variable}: Binary indicator (0=normal repayment, 1=abnormal repayment)
\end{itemize}

\textbf{EDA Key Findings}:
\begin{itemize}
    \item \textbf{Consistent Temporal Structure}: All loans have complete 14-month sequences with no variable-length issues
    \item \textbf{Mixed Data Types}: 71 integer features, 60 float features, and 14 categorical features
    \item \textbf{Credit Quality Distribution}: Credit scores range from 600-850 (excluding missing value code 9999)
    \item \textbf{Loan Characteristics}: Original loan amounts range from \$15K to \$1.7M, interest rates from 2.5\% to 9.12\%
    \item \textbf{Geographic Diversity}: Loans span multiple states and metropolitan areas
\end{itemize}

\textbf{Data Quality Assessment}:
\begin{itemize}
    \item \textbf{Temporal Features}: Zero missing values across all 112 monthly performance variables
    \item \textbf{Static Features}: Critical missing data in ReliefRefinanceIndicator (100\% missing), PreHARP\_Flag (100\% missing), SuperConformingFlag (98.92\% missing), and MSA (11.22\% missing)
    \item \textbf{Special Encodings}: Missing values encoded as 999 (DTI), 9999 (CreditScore), requiring domain-aware preprocessing
    \item \textbf{Data Integrity}: No duplicate loan indices, consistent feature formatting across datasets
\end{itemize}

\section{Challenges in Dataset}

Several significant challenges characterize this dataset and task:

\textbf{1. Semi-Supervised Learning Challenge}
\begin{itemize}
    \item Training data contains exclusively normal loans, requiring the model to learn patterns of ``normality'' without exposure to abnormal examples
    \item Validation data mixing necessitates careful evaluation strategies to avoid data leakage
\end{itemize}

\textbf{2. Class Imbalance}
\begin{itemize}
    \item Severe imbalance with only 12.61\% abnormal loans in validation set
    \item Standard accuracy metrics are misleading; Average Precision (AUPRC) becomes critical
    \item Risk of models biased toward predicting normal class
\end{itemize}

\textbf{3. High-Dimensional Mixed-Type Features}
\begin{itemize}
    \item 145 features combining numerical, categorical, and temporal data types
    \item Curse of dimensionality challenges for neighborhood-based methods
    \item Need for effective feature selection and dimensionality reduction
\end{itemize}

\textbf{4. Temporal Complexity}
\begin{itemize}
    \item Variable importance across different time periods
    \item Complex temporal dependencies and patterns
    \item Need to balance temporal modeling complexity with computational efficiency
\end{itemize}

\textbf{5. Domain-Specific Challenges}
\begin{itemize}
    \item Borrower and product heterogeneity across different loan types
    \item Economic cycle effects on repayment patterns
    \item Regulatory and market condition influences on loan performance
\end{itemize}

\textbf{6. Missing Value Handling}
\begin{itemize}
    \item Special encoding schemes (999, 9999) for missing values in critical features like DTI and CreditScore
    \item Extremely high missingness: ReliefRefinanceIndicator (100\%), PreHARP\_Flag (100\%), SuperConformingFlag (98.92\%)
    \item Geographic missingness: MSA codes missing for 11.22\% of loans
    \item Need for domain-aware imputation strategies that distinguish between truly missing data and "not applicable" cases
\end{itemize}

\textbf{7. Temporal Sequence Complexity}
\begin{itemize}
    \item All loans have exactly 14-month performance histories, eliminating variable-length sequence issues
    \item Eight concurrent time series per loan create complex multivariate temporal patterns
    \item Monthly reporting periods span multiple years with potential seasonal and economic cycle effects
    \item Temporal features may exhibit different importance across early vs. late loan lifecycle stages
\end{itemize}

\textbf{8. Feature Engineering Challenges}
\begin{itemize}
    \item 145-dimensional feature space requires sophisticated dimensionality reduction
    \item Combining static origination data with dynamic performance sequences
    \item Credit score distribution shows concentration in high-quality range (mean=753), potentially limiting discriminative power
    \item Wide loan amount distribution (\$15K-\$1.7M) may require scale-aware modeling approaches
\end{itemize}

\section{Literature Survey}

Recent research in financial anomaly detection has thoroughly explored non-deep-learning approaches due to their interpretability, robustness, and regulatory suitability. Key models include Bayesian networks, statistical algorithms, clustering, and tree-based classifiers, all of which offer strong baselines for semi-supervised loan anomaly detection.

Bayesian networks have been successfully used for credit risk anomaly detection, modeling probabilistic dependencies among borrower features and repayment data \cite{dean2024}. These approaches enable inference over conditional relationships and provide interpretable risk factor identification.

Time series anomaly detection techniques—including STL decomposition, statistical thresholds, and distance-based clustering—show proven effectiveness at capturing deviations in sequential financial data and uncovering abnormal loan behaviors \cite{informatica2025}. These methods are particularly valuable for detecting temporal patterns that traditional static models might miss.

Isolation Forests and traditional clustering methods have demonstrated value in unsupervised and semi-supervised settings, particularly for imbalanced datasets and use cases where labeled anomalies are rare \cite{expert2021}. These approaches excel at identifying outliers in high-dimensional feature spaces without requiring extensive parameter tuning.

Recent practical applications have shown that ensemble methods combining multiple anomaly detection techniques can significantly improve performance over individual approaches \cite{jetbrains2025,mindbridge2025}. These classic approaches remain essential for benchmarking and deploying scalable, explainable systems in regulated financial domains where model transparency is mandatory.

\section{Intended Approach}

Based on our preliminary experimentation with various anomaly detection methods, we have identified Local Outlier Factor (LOF) as the most promising approach for this semi-supervised loan anomaly detection task. Our experimental comparison demonstrates clear performance advantages:

\textbf{Method Comparison Results:}
\begin{itemize}
    \item \textbf{Multi-k LOF Weighted Ensemble}: AUPRC = 0.2220, AUROC = 0.6062
    \item \textbf{Optimized Single LOF (k=10)}: AUPRC = 0.1956, AUROC = 0.5752
    \item \textbf{LOF-PCA Combination}: AUPRC = 0.1867, AUROC = 0.5486
    \item Isolation Forest: AUPRC = 0.1303, AUROC = 0.5107
    \item PCA Reconstruction: AUPRC = 0.1247, AUROC = 0.5034
    \item Elliptic Envelope: AUPRC = 0.1360, AUROC = 0.5368
\end{itemize}

\textbf{Why LOF Works Best for Our Dataset:}

LOF demonstrates superior performance for several key reasons aligned with our loan dataset characteristics:

\begin{itemize}
    \item \textbf{Local Density Sensitivity}: LOF effectively captures borrower heterogeneity by comparing local neighborhoods rather than global patterns, crucial for diverse loan portfolios with varying risk profiles

    \item \textbf{High-Dimensional Robustness}: With 145 features spanning static and temporal data, LOF's distance-based approach handles dimensionality better than global methods like Isolation Forest

    \item \textbf{Temporal Pattern Recognition}: LOF can identify loans whose repayment trajectories deviate from similar borrower cohorts, making it ideal for detecting evolving default signals

    \item \textbf{Semi-Supervised Suitability}: LOF learns normal loan density patterns from training data without requiring abnormal examples, perfectly matching our problem constraints
\end{itemize}

\textbf{Proposed LOF-Based Pipeline:}

Building on these promising results, our intended approach focuses on enhancing LOF through:

\begin{itemize}
    \item \textbf{Multi-Scale LOF Ensemble}: Combining LOF detectors with varying neighborhood parameters (k=5-15) using weighted rank aggregation

    \item \textbf{Feature Engineering}: Developing domain-specific features including amortization deviations, payment burden ratios, and temporal trend indicators

    \item \textbf{Cluster-Aware Detection}: Applying LOF within borrower segments to capture subgroup-specific anomaly patterns

    \item \textbf{Meta-Learning Integration}: Using LOF outputs as features in a meta-learner for optimal combination weighting
\end{itemize}

\textbf{Future Enhancement Directions:}

We plan to explore several extensions to further improve performance:

\begin{itemize}
    \item \textbf{Advanced Temporal Modeling}: Incorporating sequence-aware distance metrics for LOF computation
    \item \textbf{Dynamic Neighborhood Selection}: Adaptive k-selection based on local data density characteristics
    \item \textbf{Hybrid Approaches}: Combining LOF with complementary methods like autoencoders for different anomaly types
    \item \textbf{Interpretability Enhancement}: Developing feature attribution methods for LOF-based anomaly explanations
\end{itemize}

This LOF-centered approach leverages our experimental insights while maintaining focus on interpretability and computational efficiency essential for financial applications.

\section{Challenges}

Several key challenges remain in our approach development:

\textbf{1. Model Generalization}
\begin{itemize}
    \item Risk of overfitting to validation set patterns
    \item Ensuring robustness across different economic conditions
    \item Balancing model complexity with interpretability requirements
\end{itemize}

\textbf{2. Feature Engineering Complexity}
\begin{itemize}
    \item Avoiding information leakage from temporal features
    \item Selecting optimal temporal windows and aggregation methods
    \item Managing computational complexity of multi-scale approaches
\end{itemize}

\textbf{3. Evaluation and Validation}
\begin{itemize}
    \item Limited labeled data for comprehensive model validation
    \item Difficulty in implementing robust cross-validation with temporal dependencies
    \item Balancing multiple evaluation metrics (AUPRC vs AUROC vs interpretability)
\end{itemize}

\textbf{4. Scalability and Deployment}
\begin{itemize}
    \item Computational efficiency for real-time scoring applications
    \item Model maintenance and updating procedures
    \item Integration with existing risk management systems
\end{itemize}

\textbf{5. Regulatory and Interpretability}
\begin{itemize}
    \item Ensuring model decisions are explainable for regulatory compliance
    \item Maintaining fairness across different borrower demographics
    \item Providing confidence intervals and uncertainty quantification
\end{itemize}

\section{References}

\begin{thebibliography}{9}

\bibitem{dean2024}
Credit Anomaly Detection Method based on Bayesian Networks, Dean Francis Press, 2024.

\bibitem{informatica2025}
Algorithms For Anomaly Detection on Time Series: A Use Case on Banking Data, Informatica, 2025.

\bibitem{expert2021}
Financial Fraud: A Review of Anomaly Detection Approaches, Expert Systems with Applications, 2021.

\bibitem{jetbrains2025}
Anomaly Detection in Time Series | The PyCharm Blog, JetBrains, 2025.

\bibitem{mindbridge2025}
Anomaly Detection Techniques: How to Uncover Risks, Identify Patterns, and Strengthen Data Integrity, MindBridge AI, 2025.

\end{thebibliography}

% ---------------------------
% Appendix
% ---------------------------
\appendix
% Single "Appendix" entry in ToC only
\addcontentsline{toc}{section}{Appendix}

% Use starred sections/subsections in Appendix to avoid ToC entries
\section*{A. Dataset Column Descriptions}
\label{appendix:dataset}

The following table provides detailed descriptions of all columns in the Freddie Mac Single-Family Loan-Level Dataset used in this project.

\subsection*{Basic Identifiers}
{\small
\begin{longtable}{|L{4cm}|L{10.5cm}|}
\hline
\textbf{Column} & \textbf{Description} \\
\hline
index & Unique identifier assigned to each loan \\
\hline
target & Binary label indicating loan performance outcome: 0 = normal loan (no default), 1 = abnormal loan (default or anomalous event) \\
\hline
\end{longtable}
}

\subsection*{Origination Variables}
{\small
\begin{longtable}{|L{4cm}|L{10.5cm}|}
\hline
\textbf{Column} & \textbf{Description} \\
\hline
CreditScore & Borrower credit score at origination (300--850). Values outside range or missing coded as 9999 \\
\hline
FirstPaymentDate & First scheduled payment due date (YYYYMM) \\
\hline
FirstTimeHomebuyerFlag & Y = Yes, N = No, 9 = Not Available \\
\hline
MaturityDate & Scheduled maturity date (YYYYMM) \\
\hline
MSA & Metropolitan Statistical Area code (null if unknown) \\
\hline
MI\_Pct & Mortgage insurance percentage. 0 = none, 1--55 = coverage \%, 999 = not available \\
\hline
NumberOfUnits & Number of dwelling units (1--4) \\
\hline
OccupancyStatus & P = Primary, I = Investment, S = Second Home, 9 = Not Available \\
\hline
OriginalCLTV & Combined Loan-to-Value ratio at origination \\
\hline
OriginalDTI & Debt-to-Income ratio (\%). Values > 65\% or missing coded as 999 \\
\hline
OriginalUPB & Original unpaid principal balance (nearest \$1{,}000) \\
\hline
OriginalLTV & Loan-to-Value ratio at origination; invalid coded as 999 \\
\hline
OriginalInterestRate & Note rate at origination \\
\hline
Channel & Origination channel: R = Retail, B = Broker, C = Correspondent, T = TPO Not Specified, 9 = Not Available \\
\hline
PPM\_Flag & Prepayment penalty: Y = Yes, N = No \\
\hline
ProductType & FRM = Fixed Rate, ARM = Adjustable Rate \\
\hline
PropertyState & Two-letter state/territory code \\
\hline
PropertyType & SF = Single-Family, CO = Condo, PU = PUD, MH = Manufactured, CP = Co-op, 99 = Not Available \\
\hline
PostalCode & Masked ZIP code (first 3 digits + ``00'') \\
\hline
LoanPurpose & P = Purchase, C = Refinance Cash Out, N = Refinance No Cash Out, R = Refinance Not Specified, 9 = Not Available \\
\hline
OriginalLoanTerm & Scheduled term in months \\
\hline
NumberOfBorrowers & Number of borrowers (1--10) \\
\hline
SellerName & Entity that sold the loan (``Other Sellers'' if below disclosure threshold) \\
\hline
ServicerName & Entity servicing the loan (``Other Servicers'' if below disclosure threshold) \\
\hline
SuperConformingFlag & Indicates whether loan exceeded conforming limits but qualified as ``super conforming'' \\
\hline
PreHARP\_Flag & Indicators for HARP and related refinance programs \\
\hline
ProgramIndicator & Program indicator for special loan programs \\
\hline
ReliefRefinanceIndicator & Relief refinance program indicator \\
\hline
PropertyValMethod & Appraisal method: 1 = ACE, 2 = Full, 3 = Other (Desktop/AVM), 4 = ACE +PDR \\
\hline
InterestOnlyFlag & Y = interest-only payments required, else N \\
\hline
BalloonIndicator & Y = balloon payment, else N \\
\hline
\end{longtable}
}

\subsection*{Performance Panel Variables}
For each loan, monthly performance data is provided across multiple periods. The prefix N indicates the month index, where N = 0,1,2,\dots,13. Each panel contains the following repeated fields:

{\small
\begin{longtable}{|L{4cm}|L{10.5cm}|}
\hline
\textbf{Column Pattern} & \textbf{Description} \\
\hline
N\_CurrentActualUPB & Current unpaid principal balance (UPB), including both interest-bearing and non-interest-bearing portions \\
\hline
N\_CurrentInterestRate & Mortgage interest rate in effect for that period \\
\hline
N\_CurrentNonInterestBearingUPB & Non-interest-bearing portion of UPB (e.g., deferred modification amounts) \\
\hline
N\_EstimatedLTV & Current estimated Loan-to-Value ratio (ELTV) from Freddie Mac's AVM. Range: 1--998, with 999 = unknown \\
\hline
N\_InterestBearingUPB & Portion of UPB that accrues interest \\
\hline
N\_LoanAge & Number of months since the loan's first payment date (or modification date) \\
\hline
N\_MonthlyReportingPeriod & Period identifier in YYYYMM format \\
\hline
N\_RemainingMonthsToLegalMaturity & Remaining months until scheduled maturity (adjusted if modified) \\
\hline
\end{longtable}
}

\subsection*{Notes}
\begin{itemize}
\item The origination variables provide static background information including borrower credit characteristics, loan terms, and property information.
\item The performance panel makes this a longitudinal dataset: each loan is tracked monthly until payoff, maturity, or default.
\item For further detail, see the official Freddie Mac user guide.
\end{itemize}

\end{document}