\documentclass[12pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{microtype} % better line breaking / justification
\usepackage{hyperref}
\usepackage[htt]{hyphenat} % allow hyphenation in long identifiers

% Hyperref link colors (no red in ToC)
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=blue,
    citecolor=black
}

% Table column helpers and spacing
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}
\renewcommand{\arraystretch}{1.2}

% Slightly relax line breaking to avoid overfull boxes in dense tables
\sloppy

% Header and footer setup
\pagestyle{fancy}
\fancyhf{}
\rhead{CS5344 Big Data Analytics}
\lhead{Loan Anomaly Detection}
\cfoot{\thepage}

\title{\textbf{Loan Anomaly Detection for Repayment Behavior Analysis} \\
       \large CS5344 Big Data Analytics Track 2: Finance}
\author{Team Project Proposal}
\date{\today}

\begin{document}

\maketitle

\tableofcontents

\section{Introduction}

In the modern financial landscape, accurate prediction of loan defaults is crucial for risk management and maintaining portfolio stability. Traditional credit scoring models primarily rely on static borrower characteristics at loan origination, potentially missing dynamic patterns that emerge during the loan lifecycle. This project addresses the challenge of \textbf{loan-level anomaly detection for repayment behavior}, where we analyze both static borrower information and temporal performance sequences to identify loans that exhibit abnormal repayment patterns.

The problem is formulated as a semi-supervised learning task where the training dataset contains exclusively normal loans (loans that meet their obligations), while the validation and test sets include both normal and abnormal loans. This mirrors real-world scenarios where financial institutions have abundant historical data on performing loans but limited labeled examples of defaults during model development phases.

Our approach leverages the rich temporal structure inherent in loan performance data, combining static origination features with dynamic monthly performance indicators to detect anomalous repayment behaviors that may signal impending default or other adverse outcomes.

\section{Project Objective}

The primary objective of this project is to develop a robust anomaly detection system capable of identifying loans with abnormal repayment patterns using a combination of static borrower characteristics and temporal performance sequences. Specifically, we aim to:

\begin{itemize}[itemsep=0.5em]
    \item \textbf{Primary Goal}: Maximize the Average Precision (AUPRC) score for detecting abnormal loans in an imbalanced dataset (87.39\% normal vs 12.61\% abnormal)
    \item \textbf{Methodological Objective}: Design a semi-supervised learning framework that effectively learns normal loan behavior patterns from training data containing only normal loans
    \item \textbf{Technical Objective}: Develop sophisticated feature engineering techniques that capture both static risk factors and temporal dynamics in loan performance
    \item \textbf{Practical Objective}: Create an interpretable and scalable solution suitable for deployment in real-world financial risk management systems
\end{itemize}

The success of our approach will be measured primarily by the Average Precision metric, which is particularly appropriate for imbalanced binary classification problems as it focuses on the precision-recall trade-off rather than overall accuracy.

\section{Target Task}

Our target task is \textbf{semi-supervised anomaly detection} in the financial domain, specifically focused on loan repayment behavior analysis. The task characteristics include:

\textbf{Problem Type}: Binary classification where we predict whether a loan exhibits normal (0) or abnormal (1) repayment behavior patterns.

\textbf{Learning Paradigm}: Semi-supervised learning, as the training data contains only normal examples (30{,}504 loans with target=0), while validation data contains both classes (4{,}693 normal, 677 abnormal loans).

\textbf{Data Structure}: Each loan $i$ is represented as:
\begin{equation}
x_i = (s_i, (t_{i,1}, r_{i,1}), (t_{i,2}, r_{i,2}), \ldots, (t_{i,T_i}, r_{i,T_i}), y_i)
\end{equation}

Where:
\begin{itemize}
    \item $s_i$ = static loan information (borrower attributes, loan terms)
    \item $\{t_{i,k}\}_{k=1}^{T_i}$ = time periods with $t_{i,1} < \ldots < t_{i,T_i}$
    \item $T_i = 14$ = number of months for loan $i$ (consistent across dataset)
    \item $r_{i,k}$ = monthly repayment information vector at time $t_{i,k}$
    \item $y_i \in \{0, 1\}$ = binary label (0=normal, 1=abnormal)
\end{itemize}

The challenge lies in learning meaningful representations that capture both static risk factors and temporal patterns indicative of abnormal repayment behavior, without having access to labeled abnormal examples during the training phase.

\section{Dataset}

Our dataset consists of loan-level data from a major financial institution, structured as follows:

\textbf{Dataset Composition}:
\begin{itemize}
    \item \textbf{Training Set}: 30{,}504 loans $\times$ 145 features (100\% normal loans)
    \item \textbf{Validation Set}: 5{,}370 loans $\times$ 145 features (87.39\% normal, 12.61\% abnormal)
    \item \textbf{Test Set}: 13{,}426 loans $\times$ 144 features (unlabeled for competition submission)
\end{itemize}

\textbf{Feature Structure}:
\begin{itemize}
    \item \textbf{Static Features (31)}: Origination variables including borrower credit score, debt-to-income ratio, loan-to-value ratio, original interest rate, loan terms, property characteristics, and demographic information
    \item \textbf{Temporal Features (112)}: Monthly performance data spanning 14 months, including current unpaid principal balance, estimated loan-to-value ratio, interest rates, loan age, and remaining maturity
    \item \textbf{Target Variable}: Binary indicator (0=normal repayment, 1=abnormal repayment)
\end{itemize}

\textbf{Temporal Structure}: Each loan contains exactly 14 months of performance history, with 8 different performance metrics tracked monthly (e.g., \texttt{N\_CurrentActualUPB}, \texttt{N\_EstimatedLTV} where N ranges from 0 to 13).

\textbf{Data Quality}: The dataset exhibits high quality with minimal missing values in temporal features, though some static features contain special missing value encodings (999, 9999) that require preprocessing.

\section{Challenges in Dataset}

Several significant challenges characterize this dataset and task:

\textbf{1. Semi-Supervised Learning Challenge}
\begin{itemize}
    \item Training data contains exclusively normal loans, requiring the model to learn patterns of ``normality'' without exposure to abnormal examples
    \item Validation data mixing necessitates careful evaluation strategies to avoid data leakage
\end{itemize}

\textbf{2. Class Imbalance}
\begin{itemize}
    \item Severe imbalance with only 12.61\% abnormal loans in validation set
    \item Standard accuracy metrics are misleading; Average Precision (AUPRC) becomes critical
    \item Risk of models biased toward predicting normal class
\end{itemize}

\textbf{3. High-Dimensional Mixed-Type Features}
\begin{itemize}
    \item 145 features combining numerical, categorical, and temporal data types
    \item Curse of dimensionality challenges for neighborhood-based methods
    \item Need for effective feature selection and dimensionality reduction
\end{itemize}

\textbf{4. Temporal Complexity}
\begin{itemize}
    \item Variable importance across different time periods
    \item Complex temporal dependencies and patterns
    \item Need to balance temporal modeling complexity with computational efficiency
\end{itemize}

\textbf{5. Domain-Specific Challenges}
\begin{itemize}
    \item Borrower and product heterogeneity across different loan types
    \item Economic cycle effects on repayment patterns
    \item Regulatory and market condition influences on loan performance
\end{itemize}

\textbf{6. Missing Value Handling}
\begin{itemize}
    \item Special encoding schemes (999, 9999) for missing values
    \item Some features with extremely high missingness (>98\%)
    \item Need for domain-aware imputation strategies
\end{itemize}

\section{Literature Survey}

Recent research in financial anomaly detection has thoroughly explored non-deep-learning approaches due to their interpretability, robustness, and regulatory suitability. Key models include Bayesian networks, statistical algorithms, clustering, and tree-based classifiers, all of which offer strong baselines for semi-supervised loan anomaly detection.

Bayesian networks have been successfully used for credit risk anomaly detection, modeling probabilistic dependencies among borrower features and repayment data \cite{dean2024}. These approaches enable inference over conditional relationships and provide interpretable risk factor identification.

Time series anomaly detection techniques—including STL decomposition, statistical thresholds, and distance-based clustering—show proven effectiveness at capturing deviations in sequential financial data and uncovering abnormal loan behaviors \cite{informatica2025}. These methods are particularly valuable for detecting temporal patterns that traditional static models might miss.

Isolation Forests and traditional clustering methods have demonstrated value in unsupervised and semi-supervised settings, particularly for imbalanced datasets and use cases where labeled anomalies are rare \cite{expert2021}. These approaches excel at identifying outliers in high-dimensional feature spaces without requiring extensive parameter tuning.

Recent practical applications have shown that ensemble methods combining multiple anomaly detection techniques can significantly improve performance over individual approaches \cite{jetbrains2025,mindbridge2025}. These classic approaches remain essential for benchmarking and deploying scalable, explainable systems in regulated financial domains where model transparency is mandatory.

\section{Intended Approach}

Our current approach demonstrates strong performance with a meta-learning ensemble achieving \textbf{AUPRC = 0.4210} and \textbf{AUROC = 0.7843} on holdout validation. The approach consists of multiple complementary strategies:

\textbf{1. Meta-Learning Stack Architecture}
\begin{itemize}
    \item Combines multiple Local Outlier Factor (LOF) detectors with varying neighborhood parameters (k=5,6,7,8)
    \item Incorporates cluster-wise LOF for capturing local anomaly patterns within borrower segments
    \item Uses amortization deviation features to detect abnormal payment patterns
    \item Employs logistic regression meta-learner for optimal combination weighting
\end{itemize}

\textbf{2. Advanced Feature Engineering}
\begin{itemize}
    \item \textbf{Amortization Analysis}: Computes expected vs. actual principal reduction patterns
    \item \textbf{Risk Indicators}: Creates financial stress signals from payment burden and equity dynamics
    \item \textbf{Temporal Patterns}: Extracts trends, volatility, and change patterns from monthly sequences
    \item \textbf{Static Ratios}: Engineers domain-specific ratios like credit-to-LTV and DTI-to-credit relationships
\end{itemize}

\textbf{3. Multi-Scale Anomaly Detection}
\begin{itemize}
    \item Global LOF detectors for overall abnormal patterns
    \item Cluster-wise LOF for segment-specific anomalies
    \item Weighted rank fusion combining multiple neighborhood scales
    \item Temporal deviation scoring for payment schedule irregularities
\end{itemize}

\textbf{4. Robust Preprocessing Pipeline}
\begin{itemize}
    \item Handles special missing value encodings (999, 9999)
    \item Forward-backward fill for temporal sequences
    \item Robust scaling and categorical encoding with unknown value handling
    \item Dimensionality reduction through strategic feature selection
\end{itemize}

\textbf{5. Planned Enhancements}
We are exploring additional approaches to further improve performance:
\begin{itemize}
    \item Deep learning architectures (LSTM autoencoders) for temporal pattern modeling
    \item Attention mechanisms for identifying critical time periods
    \item Graph neural networks for capturing feature relationships
    \item Advanced ensemble methods with dynamic weighting
\end{itemize}

The current approach effectively addresses the semi-supervised nature of the problem by learning normal patterns from training data and using sophisticated feature engineering to capture financial domain knowledge.

\section{Challenges}

Several key challenges remain in our approach development:

\textbf{1. Model Generalization}
\begin{itemize}
    \item Risk of overfitting to validation set patterns
    \item Ensuring robustness across different economic conditions
    \item Balancing model complexity with interpretability requirements
\end{itemize}

\textbf{2. Feature Engineering Complexity}
\begin{itemize}
    \item Avoiding information leakage from temporal features
    \item Selecting optimal temporal windows and aggregation methods
    \item Managing computational complexity of multi-scale approaches
\end{itemize}

\textbf{3. Evaluation and Validation}
\begin{itemize}
    \item Limited labeled data for comprehensive model validation
    \item Difficulty in implementing robust cross-validation with temporal dependencies
    \item Balancing multiple evaluation metrics (AUPRC vs AUROC vs interpretability)
\end{itemize}

\textbf{4. Scalability and Deployment}
\begin{itemize}
    \item Computational efficiency for real-time scoring applications
    \item Model maintenance and updating procedures
    \item Integration with existing risk management systems
\end{itemize}

\textbf{5. Regulatory and Interpretability}
\begin{itemize}
    \item Ensuring model decisions are explainable for regulatory compliance
    \item Maintaining fairness across different borrower demographics
    \item Providing confidence intervals and uncertainty quantification
\end{itemize}

\section{References}

\begin{thebibliography}{9}

\bibitem{dean2024}
Credit Anomaly Detection Method based on Bayesian Networks, Dean Francis Press, 2024.

\bibitem{informatica2025}
Algorithms For Anomaly Detection on Time Series: A Use Case on Banking Data, Informatica, 2025.

\bibitem{expert2021}
Financial Fraud: A Review of Anomaly Detection Approaches, Expert Systems with Applications, 2021.

\bibitem{jetbrains2025}
Anomaly Detection in Time Series | The PyCharm Blog, JetBrains, 2025.

\bibitem{mindbridge2025}
Anomaly Detection Techniques: How to Uncover Risks, Identify Patterns, and Strengthen Data Integrity, MindBridge AI, 2025.

\end{thebibliography}

% ---------------------------
% Appendix
% ---------------------------
\appendix
% Single "Appendix" entry in ToC only
\addcontentsline{toc}{section}{Appendix}

% Use starred sections/subsections in Appendix to avoid ToC entries
\section*{A. Dataset Column Descriptions}
\label{appendix:dataset}

The following table provides detailed descriptions of all columns in the Freddie Mac Single-Family Loan-Level Dataset used in this project.

\subsection*{Basic Identifiers}
{\small
\begin{longtable}{|L{4cm}|L{10.5cm}|}
\hline
\textbf{Column} & \textbf{Description} \\
\hline
index & Unique identifier assigned to each loan \\
\hline
target & Binary label indicating loan performance outcome: 0 = normal loan (no default), 1 = abnormal loan (default or anomalous event) \\
\hline
\end{longtable}
}

\subsection*{Origination Variables}
{\small
\begin{longtable}{|L{4cm}|L{10.5cm}|}
\hline
\textbf{Column} & \textbf{Description} \\
\hline
CreditScore & Borrower credit score at origination (300--850). Values outside range or missing coded as 9999 \\
\hline
FirstPaymentDate & First scheduled payment due date (YYYYMM) \\
\hline
FirstTimeHomebuyerFlag & Y = Yes, N = No, 9 = Not Available \\
\hline
MaturityDate & Scheduled maturity date (YYYYMM) \\
\hline
MSA & Metropolitan Statistical Area code (null if unknown) \\
\hline
MI\_Pct & Mortgage insurance percentage. 0 = none, 1--55 = coverage \%, 999 = not available \\
\hline
NumberOfUnits & Number of dwelling units (1--4) \\
\hline
OccupancyStatus & P = Primary, I = Investment, S = Second Home, 9 = Not Available \\
\hline
OriginalCLTV & Combined Loan-to-Value ratio at origination \\
\hline
OriginalDTI & Debt-to-Income ratio (\%). Values > 65\% or missing coded as 999 \\
\hline
OriginalUPB & Original unpaid principal balance (nearest \$1{,}000) \\
\hline
OriginalLTV & Loan-to-Value ratio at origination; invalid coded as 999 \\
\hline
OriginalInterestRate & Note rate at origination \\
\hline
Channel & Origination channel: R = Retail, B = Broker, C = Correspondent, T = TPO Not Specified, 9 = Not Available \\
\hline
PPM\_Flag & Prepayment penalty: Y = Yes, N = No \\
\hline
ProductType & FRM = Fixed Rate, ARM = Adjustable Rate \\
\hline
PropertyState & Two-letter state/territory code \\
\hline
PropertyType & SF = Single-Family, CO = Condo, PU = PUD, MH = Manufactured, CP = Co-op, 99 = Not Available \\
\hline
PostalCode & Masked ZIP code (first 3 digits + ``00'') \\
\hline
LoanPurpose & P = Purchase, C = Refinance Cash Out, N = Refinance No Cash Out, R = Refinance Not Specified, 9 = Not Available \\
\hline
OriginalLoanTerm & Scheduled term in months \\
\hline
NumberOfBorrowers & Number of borrowers (1--10) \\
\hline
SellerName & Entity that sold the loan (``Other Sellers'' if below disclosure threshold) \\
\hline
ServicerName & Entity servicing the loan (``Other Servicers'' if below disclosure threshold) \\
\hline
SuperConformingFlag & Indicates whether loan exceeded conforming limits but qualified as ``super conforming'' \\
\hline
PreHARP\_Flag & Indicators for HARP and related refinance programs \\
\hline
ProgramIndicator & Program indicator for special loan programs \\
\hline
ReliefRefinanceIndicator & Relief refinance program indicator \\
\hline
PropertyValMethod & Appraisal method: 1 = ACE, 2 = Full, 3 = Other (Desktop/AVM), 4 = ACE +PDR \\
\hline
InterestOnlyFlag & Y = interest-only payments required, else N \\
\hline
BalloonIndicator & Y = balloon payment, else N \\
\hline
\end{longtable}
}

\subsection*{Performance Panel Variables}
For each loan, monthly performance data is provided across multiple periods. The prefix N indicates the month index, where N = 0,1,2,\dots,13. Each panel contains the following repeated fields:

{\small
\begin{longtable}{|L{4cm}|L{10.5cm}|}
\hline
\textbf{Column Pattern} & \textbf{Description} \\
\hline
N\_CurrentActualUPB & Current unpaid principal balance (UPB), including both interest-bearing and non-interest-bearing portions \\
\hline
N\_CurrentInterestRate & Mortgage interest rate in effect for that period \\
\hline
N\_CurrentNonInterestBearingUPB & Non-interest-bearing portion of UPB (e.g., deferred modification amounts) \\
\hline
N\_EstimatedLTV & Current estimated Loan-to-Value ratio (ELTV) from Freddie Mac's AVM. Range: 1--998, with 999 = unknown \\
\hline
N\_InterestBearingUPB & Portion of UPB that accrues interest \\
\hline
N\_LoanAge & Number of months since the loan's first payment date (or modification date) \\
\hline
N\_MonthlyReportingPeriod & Period identifier in YYYYMM format \\
\hline
N\_RemainingMonthsToLegalMaturity & Remaining months until scheduled maturity (adjusted if modified) \\
\hline
\end{longtable}
}

\subsection*{Notes}
\begin{itemize}
\item The origination variables provide static background information including borrower credit characteristics, loan terms, and property information.
\item The performance panel makes this a longitudinal dataset: each loan is tracked monthly until payoff, maturity, or default.
\item For further detail, see the official Freddie Mac user guide.
\end{itemize}

\end{document}
